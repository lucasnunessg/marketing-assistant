from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from app.llm.llm_setup import llm as default_llm
from app.validators.topic_validator import is_marketing_question, is_follow_up_question
from app.retrieve.text_retrieve import retrieve_marketing_info as default_retriever

chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "VocÃª Ã© um especialista em marketing digital. Responda sempre com foco em vendas, redes sociais, trÃ¡fego e SEO."),
    ("user", "Quando surgiu o marketing digital?"),
    ("assistant", "O marketing digital comeÃ§ou a ganhar forÃ§a no final dos anos 1990 com a popularizaÃ§Ã£o da internet e evoluiu com o avanÃ§o das redes sociais e plataformas de publicidade online."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("system", "[Contexto de apoio]: {context}"),
    ("human", "{question}")
])

def is_related_to_history(question: str, chat_history: list[dict]) -> bool:
    for entry in chat_history:
        if 'leads' in entry['content'].lower() and 'leads' in question.lower():
            return True
    return False

def ask_llm(
    question: str,
    docs: list[str],
    chat_history: list[dict],
    llm_instance=default_llm,  # "d" do solid, da inversao de dep, eu posso mudar a ia q vai seguir funfando, posso pasasr qqr obj q tenha o invoke
    retriever=default_retriever
) -> str:
    
    context = "\n".join(docs)

    try:
        messages = chat_prompt.format_messages(
            chat_history=chat_history,
            question=question,
            context=context
        )

        response = llm_instance.invoke(messages)

        if is_related_to_history(question, chat_history):
            print("Pesquisando mais informaÃ§Ãµes...")
            search_results = retriever(question)
            additional_info = "\n".join(search_results)
            response.content += "\n\nInformaÃ§Ãµes adicionais encontradas:\n" + additional_info

        return response.content

    except Exception as e:
        print(f"Erro completo: {str(e)}")
        return f"Erro ao processar: {str(e)}"

def process_user_input(
    question: str,
    chat_history: list[dict],
    llm_instance=default_llm,
    retriever=default_retriever
) -> str:
    if not is_marketing_question(question) and not is_follow_up_question(question, chat_history):
        return "ðŸ¤– Desculpe, sÃ³ consigo responder perguntas sobre marketing digital."

 
    docs = retriever(question)
    return ask_llm(question, docs, chat_history, llm_instance=llm_instance, retriever=retriever)
