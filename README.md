# ğŸ¤– Marketing Assistant â€“ Chatbot de Marketing Digital

Este projeto Ã© um **chatbot inteligente especializado em marketing digital**, desenvolvido com:

- **Backend em Python** usando FastAPI, Langchain, Ollama e busca com DuckDuckGo
- **Frontend com React e Vite** para uma interface interativa
- **RAG (Retrieval-Augmented Generation)**: respostas com base em LLM e fontes externas

---

## ğŸ§  Funcionalidades

- GeraÃ§Ã£o de respostas contextualizadas sobre marketing digital
- RecuperaÃ§Ã£o de contexto em tempo real (via DuckDuckGo)
- ValidaÃ§Ã£o de perguntas para garantir que o conteÃºdo seja relevante
- HistÃ³rico de mensagens (chat memory)
- Interface grÃ¡fica com React + Vite
- API pÃºblica com Swagger
- Testes unitÃ¡rios com `pytest` e dependÃªncias mockadas

---

## ğŸ§° Tecnologias

### Backend

- **Python 3.11+**
- [FastAPI](https://fastapi.tiangolo.com/)
- [Langchain](https://www.langchain.com/)
- [Ollama + Gemma 2B](https://ollama.com/library/gemma:2b)
- [DuckDuckGo Search](https://pypi.org/project/duckduckgo-search/)
- [Pytest](https://docs.pytest.org/)

### Frontend

- **React 18**
- [Vite](https://vitejs.dev/)
- TypeScript
- CSS customizado

---

## ğŸ—‚ Estrutura do Projeto

.
â”œâ”€â”€ app/ # Backend (FastAPI)
â”‚ â”œâ”€â”€ api/ # Endpoints da API
â”‚ â”œâ”€â”€ chatbot/ # LÃ³gica do fluxo de conversas
â”‚ â”œâ”€â”€ llm/ # IntegraÃ§Ã£o com LLM via Langchain
â”‚ â”œâ”€â”€ prompt/ # Onde defini o comportamento inicial do bot
â”‚ â”œâ”€â”€ retrieve/ # RecuperaÃ§Ã£o de contexto via DuckDuckGo
â”‚ â”œâ”€â”€ validators/ # ValidaÃ§Ãµes de perguntas
â”‚ â””â”€â”€ tests/ # Testes unitÃ¡rios com mocks
â”œâ”€â”€ frontend/ # Frontend React + Vite
â”‚ â”œâ”€â”€ fe-marketing-assistant/ # front
â”‚     â”œâ”€â”€src
â”‚        â”œâ”€â”€assets/#logotipo
â”‚        â”œâ”€â”€components/ #onde esta o chatpage.tsx
â”‚     â”œâ”€â”€App.tsx #onde renderizei o componente
â”‚     â”œâ”€â”€index.css #css do front
â”‚     â”œâ”€â”€main.tsx #main do projeto
â”œâ”€â”€ requirements.txt # DependÃªncias do backend
â””â”€â”€ README.md # Este documento


---

## ğŸ“¦ InstalaÃ§Ã£o

### ğŸ”™ Backend (FastAPI + Langchain + Ollama)

1. Clone o repositÃ³rio e crie um ambiente virtual:

```bash
git clone https://github.com/seu-usuario/marketing-assistant.git
cd marketing-assistant
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows

Instale as dependÃªncias:

pip install -r requirements.txt

Inicie o Ollama com o modelo gemma:2b:

ollama run gemma:2b

Inicie a API (modo dev):

uvicorn app.api.main:app --reload

Acesse a documentaÃ§Ã£o da API em:
ğŸ“ http://localhost:8000/docs


ğŸ–¥ï¸ Frontend (React + Vite)

    Acesse a pasta frontend:

cd frontend

    Instale as dependÃªncias:

npm install

    Execute o servidor de desenvolvimento:

npm run dev

A interface estarÃ¡ em:
ğŸ“ http://localhost:3000


ğŸ’¬ Como funciona?

    O frontend carrega uma mensagem inicial via GET /info

    O usuÃ¡rio envia uma pergunta â†’ enviada para o backend via POST /chat

    O backend:

        Valida se a pergunta Ã© sobre marketing

        Busca contexto com DuckDuckGo (RAG)

        Usa o modelo Gemma (via Ollama) para gerar uma resposta

    A resposta Ã© retornada e exibida no chat

ğŸ§ª Testes

Execute os testes do backend com:

pytest

Os testes usam mocks e fakes, evitando chamadas reais ao LLM e Ã  internet.