# ğŸ¤– Marketing Assistant â€“ Chatbot de Marketing Digital

Este projeto Ã© um **chatbot inteligente especializado em marketing digital**, desenvolvido com:

- **Backend em Python** usando FastAPI, Langchain, Ollama e busca com DuckDuckGo
- **Frontend com React e Vite** para uma interface interativa
- **RAG (Retrieval-Augmented Generation)**: respostas com base em LLM e fontes externas

---

## ğŸ§  Funcionalidades

- GeraÃ§Ã£o de respostas contextualizadas sobre marketing digital
- RecuperaÃ§Ã£o de contexto em tempo real (via DuckDuckGo)
- ValidaÃ§Ã£o de perguntas para garantir que o conteÃºdo seja relevante
- HistÃ³rico de mensagens (chat memory)
- Interface grÃ¡fica com React + Vite
- API pÃºblica com Swagger
- Testes unitÃ¡rios com `pytest` e dependÃªncias mockadas

---

## ğŸ§° Tecnologias

### Backend

- **Python 3.11+**
- [FastAPI](https://fastapi.tiangolo.com/)
- [Langchain](https://www.langchain.com/)
- [Ollama + Gemma 2B](https://ollama.com/library/gemma:2b)
- [DuckDuckGo Search](https://pypi.org/project/duckduckgo-search/)
- [Pytest](https://docs.pytest.org/)

### Frontend

- **React 18**
- [Vite](https://vitejs.dev/)
- TypeScript
- CSS customizado

---

## ğŸ—‚ Estrutura do Projeto

```

â”œâ”€â”€ app/                        # Backend (FastAPI)
 â”‚   â”œâ”€â”€ api/                   # Endpoints da API
 â”‚   â”œâ”€â”€ chatbot/               # LÃ³gica do fluxo de conversas
 â”‚   â”œâ”€â”€ database/ # ConexÃ£o com PostgreSQL
 â”‚   â””â”€â”€ database.py # Script de conexÃ£o/configuraÃ§Ã£o
 â”‚   â”œâ”€â”€ llm/                   # IntegraÃ§Ã£o com LLM via Langchain
 â”‚   â”œâ”€â”€ prompt/                # DefiniÃ§Ã£o do comportamento inicial do bot
 â”‚   â”œâ”€â”€ retrieve/              # RecuperaÃ§Ã£o de contexto via DuckDuckGo
 â”‚   â”œâ”€â”€ validators/            # ValidaÃ§Ã£o de perguntas
 â”‚   â””â”€â”€ tests/                 # Testes unitÃ¡rios com mocks
 â”‚
 â”œâ”€â”€ frontend/                  # Frontend (React + Vite)
 â”‚   â””â”€â”€ fe-marketing-assistant/
 â”‚       â”œâ”€â”€ src/
 â”‚       â”‚   â”œâ”€â”€ assets/        # Logotipo
 â”‚       â”‚   â”œâ”€â”€ components/    # Onde estÃ¡ o ChatPage.tsx
 â”‚       â”‚   â”œâ”€â”€ App.tsx        # Onde o componente principal Ã© renderizado
 â”‚       â”‚   â”œâ”€â”€ index.css      # Estilos globais
 â”‚       â”‚   â””â”€â”€ main.tsx       # Ponto de entrada do front
 â”‚
 â”œâ”€â”€ requirements.txt           # DependÃªncias do backend
 â””â”€â”€ README.md                  # DocumentaÃ§Ã£o do projeto
 ```

---

## ğŸ“¦ InstalaÃ§Ã£o

### ğŸ”™ Backend (FastAPI + Langchain + Ollama)

1. Clone o repositÃ³rio e crie um ambiente virtual:

```bash
git clone https://github.com/seu-usuario/marketing-assistant.git
cd marketing-assistant
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows

Instale as dependÃªncias:

pip install -r requirements.txt

Inicie o Ollama com o modelo gemma:2b:

ollama run gemma:2b

Inicie a API (modo dev):

uvicorn app.api.main:app --reload

Acesse a documentaÃ§Ã£o da API em:
ğŸ“ http://localhost:8000/docs


ğŸ–¥ï¸ Frontend (React + Vite)

    Acesse a pasta frontend:

cd frontend

    Instale as dependÃªncias:

npm install

    Execute o servidor de desenvolvimento:

npm run dev

A interface estarÃ¡ em:
ğŸ“ http://localhost:3000


ğŸ’¬ Como funciona?

    O frontend carrega uma mensagem inicial via GET /info

    O usuÃ¡rio envia uma pergunta â†’ enviada para o backend via POST /chat

    O backend:

        Valida se a pergunta Ã© sobre marketing

        Busca contexto com DuckDuckGo (RAG)

        Usa o modelo Gemma (via Ollama) para gerar uma resposta

    A resposta Ã© retornada e exibida no chat

ğŸ§ª Testes

Execute os testes do backend com:

pytest

Os testes usam mocks e fakes, evitando chamadas reais ao LLM e Ã  internet.